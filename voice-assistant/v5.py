"""
ë¡œì»¬ í™˜ê²½ STT + Wake Word + GPT-4o + Google Cloud TTS (logging ì ìš©)
STT: Whisper (base)
TTS: Google Cloud Text-to-Speech
Wake Word: API ì‚¬ìš© x
GPT: GPT-4o
"""

import logging
import multiprocessing
import os
import subprocess
import time

import openai
import speech_recognition as sr
import whisper
from dotenv import load_dotenv
from gtts import gTTS

# ----------- Whisper ëª¨ë¸ ë¡œë“œ -----------
whisper_model = whisper.load_model("base")

# ----------- ë¡œê¹… ì„¤ì • -----------
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
)

# ----------- í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ -----------
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

# ----------- SYSTEM PROMPT ì„¤ì • -----------
SYSTEM_PROMPT = """
ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ìŒì„± ë¹„ì„œë¥¼ ë‹´ë‹¹í•˜ëŠ” AIì…ë‹ˆë‹¤.
ë‹¹ì‹ ì˜ ì´ë¦„ì€ ë‚˜ë¡œë´‡ì…ë‹ˆë‹¤.
ì§ˆë¬¸ì— ëŒ€í•´ ì¦‰ì‹œ ë‹µë³€í•˜ì„¸ìš”. "ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”" ê°™ì€ ë¬¸ì¥ì€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
ë¶ˆí•„ìš”í•œ ë‹¨ì–´ë¥¼ ì œê±°í•˜ê³ , ê°„ê²°í•˜ê³  ì§§ì€ ë¬¸ì¥ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.
í•­ìƒ 50ì ì´ë‚´ë¡œ ìš”ì•½í•´ì„œ ë‹µë³€í•˜ì„¸ìš”.
ë‹µë³€ì€ 1~2ê°œì˜ ë¬¸ì¥ìœ¼ë¡œë§Œ êµ¬ì„±í•˜ì„¸ìš”.
ì´ëª¨í‹°ì½˜ì„ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
ì¹œì ˆí•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ë§íˆ¬ë¥¼ ìœ ì§€í•˜ì„¸ìš”.
"""


# ----------- Whisper STT ì›Œì»¤ -----------
def whisper_stt_worker(temp_filename, result_queue):
    try:
        result = whisper_model.transcribe(temp_filename, language="ko", fp16=False, beam_size=1, best_of=1)
        text = result.get("text", "").strip()
        result_queue.put(text)
    except Exception:
        result_queue.put(None)


# ----------- STT í†µí•© í•¨ìˆ˜ -----------
def transcribe_audio_to_text(audio_data, timeout=5):
    temp_filename = "temp.wav"
    try:
        logging.info("ğŸ”„ ì˜¤ë””ì˜¤ ë°ì´í„° ì²˜ë¦¬ ì¤‘...")

        with open(temp_filename, "wb") as f:
            f.write(audio_data.get_wav_data(convert_rate=16000, convert_width=2))

        result_queue = multiprocessing.Queue()
        p = multiprocessing.Process(target=whisper_stt_worker, args=(temp_filename, result_queue))
        p.start()
        p.join(timeout)

        if p.is_alive():
            logging.warning("âš ï¸ Whisper STT ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. í”„ë¡œì„¸ìŠ¤ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            p.terminate()
            p.join()
            return None

        if not result_queue.empty():
            text = result_queue.get()
            logging.info(f"ğŸ“ ë³€í™˜ëœ í…ìŠ¤íŠ¸: {text}")
            return text
        else:
            logging.warning("âš ï¸ STT ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None

    except Exception as e:
        logging.error(f"[ERROR] STT ë³€í™˜ ì‹¤íŒ¨: {e}")
        return None
    finally:
        if os.path.exists(temp_filename):
            os.remove(temp_filename)


# ----------- ì˜¤ë””ì˜¤ ì…ë ¥ í†µí•© í•¨ìˆ˜ -----------
def handle_audio_input():
    recognizer = sr.Recognizer()
    try:
        microphone = sr.Microphone(device_index=3, sample_rate=48000, chunk_size=1024)
    except Exception as e:
        logging.error(f"[ERROR] ë§ˆì´í¬ ì¥ì¹˜ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return None

    logging.info("=======================================================")
    logging.info("ğŸ¤ ìŒì„± ë¹„ì„œê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")

    recognizer.dynamic_energy_threshold = False
    recognizer.energy_threshold = 500
    recognizer.pause_threshold = 1.0

    while True:
        try:
            with microphone as source:
                recognizer.adjust_for_ambient_noise(source, duration=1.5)
                logging.info("ğŸ™ ì§ˆë¬¸ì„ ë“£ëŠ” ì¤‘...")
                audio = recognizer.listen(source, timeout=3)

            return audio

        except sr.UnknownValueError:
            logging.warning("âš ï¸ ìŒì„±ì„ ì´í•´í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë§ì”€í•´ì£¼ì„¸ìš”.")
        except Exception as e:
            logging.error(f"[ERROR] ìŒì„± ì…ë ¥ ì˜¤ë¥˜: {e}")
            return None


# ----------- GPT ì‘ë‹µ ìƒì„± í•¨ìˆ˜ -----------
def generate_response(user_input):
    try:
        logging.info("GPT ì‘ë‹µ ìƒì„± ì¤‘...")
        response = openai.ChatCompletion.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": user_input},
            ],
            max_tokens=256,
            temperature=0.5,
        )
        assistant_response = response["choices"][0]["message"]["content"].strip()
        logging.info(f"ğŸ¤– GPT ì‘ë‹µ: {assistant_response}")
        return assistant_response
    except Exception as e:
        logging.error(f"[ERROR] GPT ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None


def speak_text(text, speed=1.3):
    try:
        timestamp = int(time.time())
        original = f"tts_{timestamp}.mp3"
        adjusted = f"tts_{timestamp}_fast.mp3"

        # 1. gTTS ìŒì„± ìƒì„±
        tts = gTTS(text=text, lang='ko')
        tts.save(original)

        # 2. ffmpegë¡œ ì¬ìƒ ì†ë„ ì¡°ì ˆ
        subprocess.run([
            "ffmpeg", "-y", "-i", original,
            "-filter:a", f"atempo={speed}",
            adjusted
        ], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

        # 3. mpg123ë¡œ mp3 ì¬ìƒ
        subprocess.run(["mpg123", adjusted], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

        # 4. ì„ì‹œ íŒŒì¼ ì‚­ì œ
        os.remove(original)
        os.remove(adjusted)

        logging.info(f"ğŸ—£ï¸ ìŒì„± ì¶œë ¥ (1.3x): {text}")
    except Exception as e:
        logging.error(f"[ERROR] ìŒì„± ì¶œë ¥ ì‹¤íŒ¨: {e}")


# ----------- ë©”ì¸ ë£¨í”„ -----------
def main():
    while True:
        try:
            audio_data = handle_audio_input()

            if not audio_data:
                continue

            transcribed_text = transcribe_audio_to_text(audio_data, timeout=5)

            if not transcribed_text:
                logging.warning("âš ï¸ í…ìŠ¤íŠ¸ ë³€í™˜ ì‹¤íŒ¨: ë‹¤ì‹œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”.")
                continue

            response = generate_response(transcribed_text)

            if not response:
                logging.warning("[WARNING] GPT ì‘ë‹µ ìƒì„± ì‹¤íŒ¨")
                continue

            logging.info(f"âœ… ìµœì¢… ì‘ë‹µ: {response}")
            speak_text(response)

        except KeyboardInterrupt:
            logging.info("\nğŸšª í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        except Exception as e:
            logging.error(f"[ERROR] ì˜ˆì™¸ ë°œìƒ: {e}")


if __name__ == "__main__":
    multiprocessing.set_start_method('fork')  # Mac/Linux
    main()
