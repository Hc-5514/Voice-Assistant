"""
ë¡œì»¬ í™˜ê²½ STT + Wake Word + GPT-4o + Google Cloud TTS (logging ì ìš©)
STT: Whisper (base)
TTS: Google Cloud Text-to-Speech
Wake Word: API ì‚¬ìš© x
GPT: GPT-4o
"""

import logging
import multiprocessing
import os
import platform
import subprocess
import sys
import time
import timeit

import openai
import speech_recognition as sr
import whisper
from dotenv import load_dotenv
from google.cloud import texttospeech

# ----------- ë¡œê·¸ ì„¤ì • -----------
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler("./logs/hc.log"),
        logging.StreamHandler()
    ]
)

# ----------- í™˜ê²½ ì„¤ì • ë° ì´ˆê¸°í™” -----------
load_dotenv()
whisper_model = whisper.load_model("base")
sys.stderr = open(os.devnull, 'w')

# GPT API í‚¤ ì„¤ì •
openai.api_key = os.getenv("OPENAI_API_KEY")
TTS_SPEAKING_RATE = float(os.getenv("TTS_SPEAKING_RATE", 1.0))
TTS_VOICE = os.getenv("TTS_VOICE", "ko-KR-Standard-A")

SYSTEM_PROMPT = """
ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ìŒì„± ë¹„ì„œë¥¼ ë‹´ë‹¹í•˜ëŠ” AIì…ë‹ˆë‹¤.
ë‹¹ì‹ ì˜ ì´ë¦„ì€ ë‚˜ë¡œë´‡ì…ë‹ˆë‹¤.
ì§ˆë¬¸ì— ëŒ€í•´ ì¦‰ì‹œ ë‹µë³€í•˜ì„¸ìš”. "ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”" ê°™ì€ ë¬¸ì¥ì€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
ë¶ˆí•„ìš”í•œ ë‹¨ì–´ë¥¼ ì œê±°í•˜ê³ , ê°„ê²°í•˜ê³  ì§§ì€ ë¬¸ì¥ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.
í•­ìƒ 50ì ì´ë‚´ë¡œ ìš”ì•½í•´ì„œ ë‹µë³€í•˜ì„¸ìš”.
ë‹µë³€ì€ 1~2ê°œì˜ ë¬¸ì¥ìœ¼ë¡œë§Œ êµ¬ì„±í•˜ì„¸ìš”.
ì´ëª¨í‹°ì½˜ì„ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
ì¹œì ˆí•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ë§íˆ¬ë¥¼ ìœ ì§€í•˜ì„¸ìš”.
"""


# ----------- Wake Word ë¡œë”© (.envì—ì„œ ì½ì–´ì˜¤ê¸°) -----------
def load_wake_word_actions():
    raw = os.getenv("WAKE_WORDS", "")
    wake_word_actions = {}
    if raw:
        pairs = raw.split(',')
        for pair in pairs:
            if ':' in pair:
                keyword, response = pair.split(':', 1)
                wake_word_actions[keyword.strip()] = response.strip()
    return wake_word_actions


wake_word_actions = load_wake_word_actions()


def process_wake_word(text):
    for wake_word, response in wake_word_actions.items():
        if wake_word in text:
            logging.info(f"âœ… Wake Word ê°ì§€ë¨: {wake_word}")
            speak_text(response)
            return True
    return False


# ----------- Whisper STT ì›Œì»¤ -----------
def whisper_stt_worker(temp_filename, result_queue):
    try:
        result = whisper_model.transcribe(temp_filename, language="ko", fp16=False, beam_size=1, best_of=1)
        text = result.get("text", "").strip()
        result_queue.put(text)
    except Exception:
        result_queue.put(None)


# ----------- STT í†µí•© í•¨ìˆ˜ -----------
def transcribe_audio_to_text(audio_data, timeout=5):
    temp_filename = "temp.wav"
    try:
        logging.info("ğŸ”„ ì˜¤ë””ì˜¤ ë°ì´í„° ì²˜ë¦¬ ì¤‘...")

        with open(temp_filename, "wb") as f:
            f.write(audio_data.get_wav_data(convert_rate=16000, convert_width=2))

        result_queue = multiprocessing.Queue()
        p = multiprocessing.Process(target=whisper_stt_worker, args=(temp_filename, result_queue))
        p.start()
        p.join(timeout)

        if p.is_alive():
            logging.warning("âš ï¸ Whisper STT ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. í”„ë¡œì„¸ìŠ¤ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            p.terminate()
            p.join()
            return None

        if not result_queue.empty():
            text = result_queue.get()
            logging.info(f"ğŸ“ ë³€í™˜ëœ í…ìŠ¤íŠ¸: {text}")
            return text
        else:
            logging.warning("âš ï¸ STT ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None

    except Exception as e:
        logging.error(f"[ERROR] STT ë³€í™˜ ì‹¤íŒ¨: {e}")
        return None
    finally:
        if os.path.exists(temp_filename):
            os.remove(temp_filename)


def handle_audio_input():
    recognizer = sr.Recognizer()
    microphone = sr.Microphone()

    logging.info("=======================================================")
    logging.info("ğŸ¤ ìŒì„± ë¹„ì„œê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")

    recognizer.dynamic_energy_threshold = False
    recognizer.energy_threshold = 500
    recognizer.pause_threshold = 1.0

    while True:
        try:
            with microphone as source:
                recognizer.adjust_for_ambient_noise(source, duration=1.5)
                logging.info("ğŸ™ ì§ˆë¬¸ì„ ë“£ëŠ” ì¤‘...")
                audio = recognizer.listen(source, timeout=None)
            return audio
        except sr.UnknownValueError:
            logging.warning("âš ï¸ ìŒì„±ì„ ì´í•´í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë§ì”€í•´ì£¼ì„¸ìš”.")
        except Exception as e:
            logging.error(f"[ERROR] ìŒì„± ì…ë ¥ ì˜¤ë¥˜: {e}")


# ----------- GPT ì‘ë‹µ ìƒì„± í•¨ìˆ˜ -----------
def generate_response(user_input):
    try:
        logging.info("GPT ì‘ë‹µ ìƒì„± ì¤‘...")
        response = openai.ChatCompletion.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": user_input},
            ],
            max_tokens=100,
            temperature=0.5,
        )
        assistant_response = response["choices"][0]["message"]["content"].strip()
        logging.info(f"ğŸ¤– GPT ì‘ë‹µ: {assistant_response}")
        return assistant_response
    except Exception as e:
        logging.error(f"[ERROR] GPT ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None


# ----------- Google Cloud TTS ìŒì„± ì¶œë ¥ í•¨ìˆ˜ -----------
def speak_text(text):
    try:
        timestamp = int(time.time())
        wav_file = f"tts_{timestamp}.wav"

        client = texttospeech.TextToSpeechClient()

        synthesis_input = texttospeech.SynthesisInput(text=text)

        voice = texttospeech.VoiceSelectionParams(
            language_code="ko-KR",
            name=TTS_VOICE,
            ssml_gender=texttospeech.SsmlVoiceGender.NEUTRAL
        )

        audio_config = texttospeech.AudioConfig(
            audio_encoding=texttospeech.AudioEncoding.LINEAR16,
            speaking_rate=TTS_SPEAKING_RATE
        )

        response = client.synthesize_speech(
            input=synthesis_input,
            voice=voice,
            audio_config=audio_config
        )

        with open(wav_file, "wb") as out:
            out.write(response.audio_content)

        if platform.system() == "Darwin":
            subprocess.run(["afplay", wav_file])
        else:
            subprocess.run(["aplay", wav_file])

        os.remove(wav_file)

    except Exception as e:
        logging.error(f"[ERROR] ìŒì„± ì¶œë ¥ ì‹¤íŒ¨: {e}")


# ----------- Main -----------

def main():
    while True:
        try:
            audio_data = handle_audio_input()

            if not audio_data:
                logging.warning("âš ï¸ ì˜¤ë””ì˜¤ ë…¹ìŒ ì‹¤íŒ¨")
                continue

            start_time = timeit.default_timer()

            transcribed_text = transcribe_audio_to_text(audio_data)

            if not transcribed_text:
                logging.warning("âš ï¸ í…ìŠ¤íŠ¸ ë³€í™˜ ì‹¤íŒ¨: ë‹¤ì‹œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”.")
                continue

            if process_wake_word(transcribed_text):
                continue

            response = generate_response(transcribed_text)
            if not response:
                logging.warning("[WARNING] GPT ì‘ë‹µ ìƒì„± ì‹¤íŒ¨")
                continue

            speak_text(response)
            end_time = timeit.default_timer()
            elapsed_time = end_time - start_time
            logging.info(f"â³ ì‹¤í–‰ ì‹œê°„: {elapsed_time:.3f}ì´ˆ")

        except KeyboardInterrupt:
            logging.info("\nğŸšª í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        except Exception as e:
            logging.error(f"[ERROR] ì˜ˆì™¸ ë°œìƒ: {e}")


if __name__ == "__main__":
    main()
